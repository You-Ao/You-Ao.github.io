---
author: false
title: PG-Agent å¤ç°
mathjax: true
order: 1
date: 2025-11-24
category:
    - äººå·¥æ™ºèƒ½
---

ä»£ç è§ [GitHub](https://github.com/You-Ao/PG-Agent-rev)

## ç¯å¢ƒå‡†å¤‡

```bash
pip install langchain langchain-classic langchain-community langchain-huggingface sentence-transformers jax jaxlib peft transformers faiss-cpu
```

:::warning faiss
æ­¤å¤„é€‰æ‹© `faiss-cpu` æ˜¯å› ä¸º `faiss-gpu` éœ€è¦ `numpy < 2.0`ï¼Œä½† `langchain` ç³»åˆ—åŒ…éœ€è¦ `numpy >= 2.0`ï¼ŒäºŒè€…å†²çªï¼Œæ•…åªèƒ½é€‰æ‹© `faiss-cpu`
:::

å¤§æ¨¡å‹éƒ¨åˆ†ï¼š

æ›¾ä½¿ç”¨ `API` è¿›è¡Œæµ‹è¯•ï¼Œä½† `API` éš¾ä»¥è´Ÿæ‹…æ•´ä¸ªæµ‹è¯•é›†çš„è®­ç»ƒå’Œè¯„æµ‹éœ€æ±‚ï¼ˆä»·æ ¼è¿‡äºæ˜‚è´µğŸ˜°ï¼‰æ•…ä½¿ç”¨ `vllm` è¿›è¡Œæœ¬åœ°éƒ¨ç½² `openai` å…¼å®¹æœåŠ¡å™¨ï¼ˆå€ŸåŠ©â€œè®¡ç®—æœºè§†è§‰å¯¼è®ºâ€è¯¾ç¨‹é›†ç¾¤ğŸ¤—ï¼‰

ç¯å¢ƒé…ç½®ä»…éœ€å®‰è£… `vllm`: 

```bash
pip install vllm
```
ğŸ˜­ ç”±äºé›†ç¾¤é™åˆ¶ï¼Œåªèƒ½é€‰ç”¨æ¨¡å‹ï¼š`Qwen/Qwen3-VL-30B-A3B-Instruct` è¿è¡Œåœ¨ 4 å¼  `Tesla V100-SXM2-32GB`

vllm å¯åŠ¨å‘½ä»¤ï¼š

```bash
vllm serve Qwen/Qwen3-VL-30B-A3B-Instruct --tensor-parallel-size 4 --limit-mm-per-prompt.video 0 --async-scheduling
```

å¯ä½¿ç”¨ `http://localhost:8000/v1/` ä¸è¯¥æ¨¡å‹è¿›è¡Œäº¤äº’

## ä»£ç ä¿®æ”¹

é‡å†™ `chat` å‡½æ•°ï¼Œä¸å†è‡ªè¡Œæ‹¼æ¥ `http` è¯·æ±‚å‘é€ï¼Œä½¿ç”¨ `openai` åŒ…å‘é€å’Œæ¥æ”¶è¯·æ±‚

```python
def chat(img_url_list: list[str] = '', query: str = '') -> dict:
    client = OpenAI(
        api_key="",
        base_url="http://localhost:8000/v1/",
    )

    messages = []
    messages.append({"role": "system", "content": "You are a helpful assistant."})

    content = []
    for img_url in img_url_list:
        content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encode_image(img_url)}"}})
    content.append({"type": "text", "text": query})

    messages.append({"role": "user", "content": content})
    
    completion = client.chat.completions.create(
        model="Qwen/Qwen3-VL-30B-A3B-Instruct",
        messages=messages,
        stream=False
    )

    response = completion.choices[0].message.content

    # with open("response.txt", "a") as f:
    #     f.write(response)
    #     f.write("\n")

    return response
```

åŒæ—¶ä¿®æ”¹äº†å›¾ç‰‡çš„å‘é€æ–¹å¼ï¼Œå°†å›¾ç‰‡ç¼–ç ä¸º `base64` åè¿›è¡Œå‘é€ï¼Œç¼–ç ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
```

ç”±äºä½¿ç”¨äº†æ–°ç‰ˆæœ¬ `langchain` åŒ…ï¼Œéƒ¨åˆ†å‡½æ•°åœ¨åŒ…ä¸­çš„ä½ç½®è¢«æ›´æ”¹ï¼Œå¯¹ `import` è¿›è¡Œä¿®è¡¥

```python
from langchain_community.vectorstores.faiss import FAISS
from langchain_classic.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
```

ä» `https://github.com/google-research/google-research/tree/master/android_in_the_wild` è·å¾—æ–‡ä»¶ `action_type.py`ï¼Œä¾› `workflow/` ä¸­çš„æµ‹è¯•æ–‡ä»¶ä½¿ç”¨

## æ•°æ®é›†å‡†å¤‡

ä»…é’ˆå¯¹ `Mind2Web` æ•°æ®é›†è¿›è¡Œæµ‹è¯•

ä» `README.md` æ–‡ä»¶æŒ‡å‘çš„ç½‘å€ä¸‹è½½æ•°æ®é›†å’Œæ ‡æ³¨

```
mind2web_images.zip:
https://box.nju.edu.cn/f/33e203d170ab48b0b922/?dl=1
mind2web_annots.zip:
https://box.nju.edu.cn/f/e30b861fa7604668821b/?dl=1
```

## è¿è¡Œ

é¦–å…ˆè¿è¡Œ `document_construction/mind2web_document/main.py` è¿›è¡Œè®­ç»ƒ

è®­ç»ƒé‡ä¸åŸä»£ç ä¿æŒä¸€è‡´ï¼Œä¸º 100ï¼Œè·å¾—æ–‡ä»¶ `mind2web_library.json`

è¿è¡Œ `workflow/mind2web/mind2web_test.py` è¿›è¡Œæµ‹è¯•

é€‰æ‹© `--task test` å…± 252 ä¸ªæµ‹è¯•

## ç»“æœ

è®­ç»ƒå¾—åˆ°çš„ç»“æœè§æ–‡ä»¶ `mind2web_library.json`

æµ‹è¯•çš„å…¨éƒ¨è¾“å‡ºè§æ–‡ä»¶ `task_result.txt`

è®ºæ–‡ä¸­çš„ç»“æœä¸ºï¼š

![](./pic/pg-agent/result1.png)
![](./pic/pg-agent/result2.png)
![](./pic/pg-agent/result3.png)